# Cleaning-medical_data
The next step to the Data Analytics Life Cycle involves preparing the data for analysis, a process known as data cleaning. 

### Research Question
How do readmission rates vary across different levels of complication risk for specific medical conditions?

### Why use R?
This data analysis and cleaning was performed in R. The language provides a more straightforward way to do statistical analysis and data visualization compared to Python. I found it quite effortless to perform data cleaning using R. It was a seamless transformation to different data types and formats. Data manipulation was also made simple due to the powerful libraries that facilitate efficient filtering, sorting, and transforming data. The libraries and packages were easy to install and use in Rstudio. The following packages were utilized for this analysis: tidyverse, naniar, and base R libraries. 
Firstly, tidyverse provides several packages that are essential for analysts. This analysis used dplyr for data manipulation, ggplot2 for data visualization, tidyr for data tidying, reshape2 for data reshaping and plyr for more data manipulation. Naniar, on the other hand, is used to discover missing data. This package provides a summary and visualization, both vital to analyzing missing data patterns. Lastly, the base R libraries, such as readxl and stats, are used to read Excel files and perform statistics calculations, respectively. 
### What methods were used to detect the data quality issues?
To find duplicates, use duplicated(). Missing values are discovered using is.na(), miss_var_summary() and miss_case_summary(). Outliers are visualized using geom_boxplot(),and ggplot(). For reexpressing variables, as.numeric() and as.factor() was utilized for this analysis.
### Why use the methods were used to detect the data quality issues?
To detect duplicates, I primarily used duplicated(). Additional capabilities using count() to count occurrences of a specific variable where n is greater than 1, which indicates duplicates, were also used for this analysis. 
To find missing values, the is.na() was vital to indicate if a data frame has missing values. This method will display a ‘True’ for missing values and a ‘False’ for non-missing values. Furthermore, sum() and colSums() count the total missing values in the whole dataset and each column. miss_var_summary() and miss_case_summary() from naniar are used to summarize information about missing values at the column (variable) and row (case) levels, respectively.
To find outliers, visualization was used to highlight the extreme values and data points that fall outside of the typical range. The geom_boxplot() is a simple way to provide a visual representation as a boxplot of the distribution of a variable. The ggplot() can be used to make a box plot of multiple items to compare distributions. 
Lastly, to reexpress variables in this analysis, as.numeric() and as.factor() were used in 17 variables to create uniformity. The round() was also used to round out the values for days to the nearest whole number.

### Discuss what you found
Using the previous code attached, here are my findings. The dataset has no duplicates. On the other hand, there are 12955 missing values or NAs. Children have the most missing values, with 2588 or 25.9% missing values. Soft drink takes the second with 2467 or 24.7% missing values. Income is next with 2464 or 24.6% missing values. Age has 2414 or 24.1% missing values. Initial days have 1056 or 10.6% missing values. Anxiety has 984 or 9.8% missing values. Lastly, overweight has 982 or 9.8% missing values. 
There were 21 quantitative variables to detect for outliers. Namely, the case order, zip, latitude, longitude, population, children, age, income, vitamin D supplement, vitamin D levels, doctor visits, full meals eaten, initial days, total charge, additional charges, item1, item2, item3, item4, item5, item6, item7 and item8. Out of the 19 variables, 16 had outliers. Population had the most outliers, with 855 outliers. Vitamin D levels is next with 534 outliers. Total charges has 466 outliers. The survey items 4, 1, 3, 5, 6, 8, 7, and 2 have 450, 449, 443, 443, 443, 442, 438, and 429 outliers, respectively. Additional charges have 424 outliers. Children have 303 outliers. Income has 252 outliers. Longitude has 237 outliers. Latitude has 150 outliers. Vitamin D supplement has 70 outliers. Lastly, full meals eaten has 8 outliers. Case order, zip, age, doctor visits and initial days has no outliers. 
### Discuss what you did to treat and why you used the treatment method
Since there are no duplicates, no treatment methods for duplicates were used.
To treat missing variables, the mice (Multivariate Imputation by Chained Equations) package is used to perform the imputation of missing data. Predictive Mean Matching (PMM) was employed as the imputation method. Each imputation needs predictor values to perform the process. The goal is to use information from other observed variables to impute the missing values. There were 7 variables: children, soft drink, income, age, initial days, anxiety, and overweight that had missing values. The mice package was used for all these variables. Marital, age, and employment were used as predictor values for children. Age, diabetes, and overweight were used as predictor values for soft drink. Education, employment, age, marital and children were used to impute income. Education, employment, income, marital and children were used to impute age. Initial admin, doc visits, services, high blood, and diabetes were used to impute initial days. Age, gender, income, education, and services were used to impute anxiety. Age, gender, high blood, diabetes, hyperlipidemia, arthritis, back pain, asthma, and soft drink were used to impute overweight. The imputation model was used for all these variables since it preserves the sample size. Retaining data is crucial when 4 out of the 9 variables have approximately 25% missing data. Dropping these cases might result in a smaller sample size, leading to less precision. 
Winsorization, and retention methods were used to treat outliers. Using the dplyr package, winsorization was used in the variables population, age, income, vitamin D supplements, vitamin D levels, total charge, and additional charges. Winsorizing is replacing extreme values with less extreme ones using a specified data percentile. For population, the 91st percentile was used for the upper limit and the 9th percentile for the lower limit. For children, the 94th percentile was used for the upper limit, and the 6th percentile was used for the lower limit. For income, the 96th percentile was used for the upper limit, and the 4th percentile for the lower limit. For vitamin D supplements, the 99th percentile was used for the upper limit, and the 1st percentile was used for the lower limit. For vitamin D levels, the 94th percentile was used for the upper limit, and the 6th percentile was used for the lower limit. For the total charge, the 95th percentile was used for the upper limit, and the 5th percentile was used for the lower limit. For the additional charges, the 95th percentile was used for the upper limit, and the 5th percentile was used for the lower limit. Winsorizing helps address the outliers while preserving the sample size. Moreover, winsorizing was simple and flexible. Choosing the percentile to customize to the needs of the variable was a matter of trial and error. This process was made easier since there were visuals.  For this analysis, the winsorized variables are in a new column to provide flexibility and maintain the integrity of the original data set. There were variables that I chose to retain. Variables like latitude and longitude were retained because these are geographical data. Item 1 to Item 8 was also retained since the outliers are expected for the data. The outlier values were within the range of values in the survey questions. Lastly, full meals eaten outliers were retained since there were only 8 cases. This is 0.08% of the cases, which I consider to be insignificant. 
Multiple variables underwent reexpression. Children, age, income, and initial days were originally classified as char (character) data type. These variables were converted into numeric, with initial days rounded to the nearest whole number. Since these variables are numeric, they should be converted to numeric. Soft drink and medical conditions: high blood, stroke, overweight, arthritis, diabetes, hyperlipidemia, back pain, anxiety, allergic rhinitis, reflux esophagitis, and asthma were converted to num (numeric) data type. “Yes ” was revalued to 1, “No” was revalued to 0, and NA stayed as NA. Since these variables are Boolean variables, converting them to numeric values shows uniformity throughout the data set. Consistency and standardization make it easier for different analysts to consistently work with the same data. Complication risk was revalued as a factor with levels “Low,” “Medium,” and “High.” This reexpresion to a factor enables analysis to reflect the distinct categories. The levels also help convey the meaning of each category and improve the understanding of the data. 
### Summarize all the work performed
No duplicates were found. 
Missing values were imputed using predictor values. Using the mice package, imputation was performed for several variables: children, soft drink, income, age, initial days, anxiety, and overweight. This iterative process is repeated for each variable until all missing data is handled. Using the naniar package to show missing data, the result is now 0 missing and 0% missing.
Outliers were winsorized or retained. Using the dplyr package, winsorizing was performed for several variables, such as population, children, income, vitamin D supplement, vitamin D levels, total charge, and additional charges. For the winsorized variables, boxplots show that there are no outliers. Winsorizing involves setting lower and upper limits for each variable, which are then used to replace the extreme values. The winsorized variables are in new columns to maintain data integrity. Boxplots for the new winsorized column show no outliers (see below). Variables that were retained remained the same. 
Before treatment of the missing data and outliers, variables need to be reexpressed into their correct data type. Variables such as children, age, income, and initial days were first to be reexpressed. These variables were converted to numeric format, ensuring null values stay null. The variables soft drink and medical conditions such as high blood, stroke, arthritis, diabetes, hyperlipidemia, back pain, allergic rhinitis, reflux esophagitis, and asthma were converted to numeric format with Yes as 1, No as 0, and NA as NA. This reexpression enhances the dataset’s consistency by ensuring numeric formats for numeric variables. The final dataset is now more standardized and uniform. Below is the str() function that shows the reexpressed variables' final data type, length, components, and attributes. 

### Disadvantages of the methods used
There are drawbacks to the imputation method in handling missing data. Firstly, the method assumes that there is a linear relationship between variables. If it is nonlinear, imputed values may be inaccurate to the true pattern in the data. It is also important to note that the imputed values are estimates. It is important to note that the process introduces uncertainty, which does not fully capture the complexity of the missing data.
Winsorizing can be beneficial, but it has its disadvantages. Firstly, the process assumes a symmetric distribution of data. It may introduce a distortion in the distribution and affect statistical interpretations. There is also a risk that valid extreme values will be replaced. If genuine outliers are present, this process could result in the loss of important cases.
Furthermore, reexpression is subjective and dependent on me. Different choices may lead to different results and interpretations, especially for converting the medical conditions into numeric. This may also introduce a loss of information. Extreme transformation can obscure patterns that might be important for the dataset. 
### Challenges from the now-cleaned data
There are potential challenges and limitations to using my cleaned data.
Firstly, imputing missing values involves making assumptions about the relationship between variables. if the assumptions are inaccurate, imputed values could introduce bias into the analysis. Moreover, winsorizing may have altered the distribution of variables. The variability might cause distortion and affect the statistical properties of the variables when analyzing variables. In addition, variable conversion loss and data loss through NAs handling may lead to oversimplification of the information they originally carried. This could impact the identification of nuanced relationships between variables.
Overall, it is crucial for the data analyst to assess the data themselves. They should read the report on data cleaning procedures and how it will impact the research question.  



